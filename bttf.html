<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    
    <title>Save Marty</title>

    <style>
      body {
        margin: 0;
        display: flex;
        height: 100vh;
        justify-content: center;
      }

      #back{
       position:absolute;
       z-index: 10;
       width: 100px;
       height:100px;
       margin-top: 20%;
       margin-left: -98%;
       filter: brightness(1000%);
     }

    </style>
  </head>

  <body>

    
  
    <div style="display: none;">
      <img id='nofamily' src="images/nofamily.png" alt="McFly Family">
    </div>
    
    <div  style="display: none;">
        <img id='family' src="images/family.png" alt="McFly Family">
    </div>

    <canvas width="1572" height="1418" style="width: 786px; height: 709px;"></canvas>


    <a href='https://i6.cims.nyu.edu/~zh1278/380/audio'><img id='back' src='arrow.png'></a>

    
    <script>
      const canvas = document.querySelector('canvas');
      const context = canvas.getContext('2d');
      const image = document.getElementById('family');
      const image2 = document.getElementById('nofamily');

      let width;
      let height;

      let pxScale = window.devicePixelRatio;

      var song = new Audio();
      song.src = "EarthAngel.mp3";

      function setup() {
        width = window.innerWidth;
        height = window.innerHeight;

        canvas.style.width = width + 'px';
        canvas.style.height = height + 'px';

        canvas.width = width * pxScale;
        canvas.height = height * pxScale;

        context.scale(pxScale, pxScale);

        draw();
      }



        navigator.mediaDevices.getUserMedia({ audio: true, video: false })
        .then(function(stream) {
          audioContext = new AudioContext();
          analyser = audioContext.createAnalyser();
          microphone = audioContext.createMediaStreamSource(stream);
          javascriptNode = audioContext.createScriptProcessor(2048, 1, 1);

          analyser.smoothingTimeConstant = 0.8;
          analyser.fftSize = 1024;

          microphone.connect(analyser);
          analyser.connect(javascriptNode);
          javascriptNode.connect(audioContext.destination);
          javascriptNode.onaudioprocess = function() {
              var array = new Uint8Array(analyser.frequencyBinCount);
              analyser.getByteFrequencyData(array);
              var values = 0;

              var length = array.length;
              for (var i = 0; i < length; i++) {
                values += (array[i]);
              }

              var average = values / length;

            console.log(Math.round(average));
            // colorPids(average);

            if ( (Math.round(average)) > 25) {
            directionX = 1;
            
            } else if ( (Math.round(average)) < 25 ) {
                directionX = -1;
        }
          }
          })
          .catch(function(err) {
            /* handle the error */
        });


      let directionX = 1;
      let opacity = 0;

      function draw() {
        context.globalAlpha = 1;
        context.drawImage(image2, 0, 0, window.innerWidth, window.innerHeight);
        opacity += directionX * .006;
        if (opacity < 0) {
          opacity = 0
        }
        if (opacity > 1){
          opacity = 1
        }
        context.globalAlpha = opacity;
        context.drawImage(image, 0, 0, window.innerWidth, window.innerHeight);

        requestAnimationFrame(draw);
      }


      counter = 1;
      
      function audio() {
        song.volume = 0.5;
        counter += 1;

        if ((counter % 2) == 0){
          song.play();
        }
        else if ((counter % 2) != 0){
          song.pause();
        }


      }




      window.addEventListener('load', setup);
      window.addEventListener('click', audio);

      //window.addEventListener('resize', setup);
    </script>
  
  </body>
</html>